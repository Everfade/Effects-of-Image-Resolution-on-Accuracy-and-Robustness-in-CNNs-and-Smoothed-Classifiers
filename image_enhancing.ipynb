{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LBGty4O_0ukJ"
   },
   "source": [
    "**Preparing Environment**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:37:55.129336Z",
     "iopub.status.busy": "2022-04-27T11:37:55.128960Z",
     "iopub.status.idle": "2022-04-27T11:37:57.455457Z",
     "shell.execute_reply": "2022-04-27T11:37:57.454915Z"
    },
    "id": "lnyLTyUt0ukN"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "from PIL import Image, ImageFilter\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import tensorflow_hub as hub\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "import cv2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.environ[\"TFHUB_DOWNLOAD_PROGRESS\"] = \"True\"\n",
    "# Declaring Constants\n",
    "IMAGE_PATH = \"D:/MachineLearningData/MNSTP/mnist_p/testing/0/1.png\"\n",
    "SAVED_MODEL_PATH = \"https://tfhub.dev/captain-pool/esrgan-tf2/1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = Image.open('D:/MachineLearningData/MNSTP/mnist_p/normal/training/0/1.png')\n",
    "img=img.resize((128,128),Image.BICUBIC)\n",
    "img.save(\"%s\" % \"0control.png\")\n",
    "img.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:37:57.657924Z",
     "iopub.status.busy": "2022-04-27T11:37:57.657412Z",
     "iopub.status.idle": "2022-04-27T11:37:57.663797Z",
     "shell.execute_reply": "2022-04-27T11:37:57.663267Z"
    },
    "id": "IslbQmTj0ukz"
   },
   "outputs": [],
   "source": [
    " def add_noise(img,mean,sigma,size):\n",
    "        x,y=size\n",
    "        img=img/255\n",
    "        n=np.random.normal(loc=mean,scale=sigma,size=(x,y))\n",
    "        return (img+n)*255\n",
    "    \n",
    "def preprocess_image(image_path):\n",
    "    hr_image = tf.image.decode_image(tf.io.read_file(image_path))\n",
    "  # If PNG, remove the alpha channel. The model only supports\n",
    "  # images with 3 color channels.abs\n",
    "    if hr_image.shape[-1] == 4:\n",
    "        hr_image = hr_image[...,:-1]\n",
    "    hr_size = (tf.convert_to_tensor(hr_image.shape[:-1]) // 4) * 4\n",
    "    hr_image = tf.image.crop_to_bounding_box(hr_image, 0, 0, hr_size[0], hr_size[1])\n",
    "    hr_image = tf.cast(hr_image, tf.float32)\n",
    "    return tf.expand_dims(hr_image, 0)\n",
    "\n",
    "def save_image(image, filename):\n",
    "  if not isinstance(image, Image.Image):\n",
    "    image = tf.clip_by_value(image, 0, 255)\n",
    "    image = Image.fromarray(tf.cast(image, tf.uint8).numpy())\n",
    "  image.save(\"%s\" % filename)\n",
    "  print(\"Saved as %s\" % filename)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def downscaleDataset(path,destination):\n",
    "           \n",
    "            for filename in os.listdir(path):\n",
    "                print(filename+\"/10\")\n",
    "                f=os.path.join(path,filename)#full path\n",
    "                for file in os.listdir(f):\n",
    "                    img = Image.open(os.path.join(f,file))\n",
    "                    img=img.resize((56,56),Image.BICUBIC)\n",
    "                    img.save(\"%s\" % destination+filename+\"/\"+file)\n",
    "            print(\"Downscaling complete\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def addNoiseToDataSet(path,destination):\n",
    "    print(\"starting\")\n",
    "    for filename in os.listdir(path):\n",
    "            print(filename+\"/10\")\n",
    "            f=os.path.join(path,filename)#full path\n",
    "            for file in os.listdir(f):\n",
    "                image=cv2.imread( os.path.join(f,file),0)\n",
    "                image=add_noise(image,sigma=0.15,mean=0)\n",
    "                cv2.imwrite(destination+filename+\"/\"+file,image)\n",
    "    print(\"Noising complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2022-04-27T11:37:57.666564Z",
     "iopub.status.busy": "2022-04-27T11:37:57.666241Z",
     "iopub.status.idle": "2022-04-27T11:37:57.671942Z",
     "shell.execute_reply": "2022-04-27T11:37:57.671465Z"
    },
    "id": "uh1E2rBpnWxV"
   },
   "outputs": [],
   "source": [
    "def upscaleDataset(path,destination):\n",
    "    print(\"loading model\")\n",
    "    model = hub.load(SAVED_MODEL_PATH)\n",
    "    print(\"starting\")\n",
    "    for filename in os.listdir(path):\n",
    "        if(int(filename)==4):\n",
    "            print(filename+\"/10\")\n",
    "            f=os.path.join(path,filename)#full path\n",
    "            for file in os.listdir(f):\n",
    "                hr_image=preprocess_image( os.path.join(f,file))\n",
    "                image3channel = tf.image.grayscale_to_rgb(hr_image)\n",
    "                fake_image = model(image3channel)\n",
    "                fake_image = tf.squeeze(fake_image)\n",
    "                save_image(fake_image, filename=destination+filename+\"/\"+file)\n",
    "        print(\"upscaling complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "upscaleDataset(\"D:/MachineLearningData/MNSTP/mnist_p/testing/\",\n",
    "               \"D:/MachineLearningData/MNSTP/mnist_p//testingUpscaled/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    " addNoiseToDataSet(\"D:/MachineLearningData/MNSTP/mnist_p/Upscaled/train/\",\n",
    "               \"D:/MachineLearningData/MNSTP/mnist_p/Upscaled/trainNoise/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0/10\n",
      "1/10\n",
      "2/10\n",
      "3/10\n",
      "4/10\n",
      "5/10\n",
      "6/10\n",
      "7/10\n",
      "8/10\n",
      "9/10\n",
      "Downscaling complete\n"
     ]
    }
   ],
   "source": [
    "downscaleDataset(\"D:/MachineLearningData/MNSTP/mnist_p/Normal/train/\",\n",
    "               \"D:/MachineLearningData/MNSTP/mnist_p/Control/trainUpscaledFake/\")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "image_enhancing.ipynb",
   "private_outputs": true,
   "provenance": [],
   "toc_visible": true
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
